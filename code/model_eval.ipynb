{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.contrib.keras.python import keras\n",
    "from tensorflow.contrib.keras.python.keras import layers, models\n",
    "\n",
    "from tensorflow import image\n",
    "\n",
    "from utils import scoring_utils\n",
    "from utils.separable_conv2d import SeparableConv2DKeras, BilinearUpSampling2D\n",
    "from utils import data_iterator\n",
    "from utils import plotting_tools \n",
    "from utils import model_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_file_name = 'model_eval'\n",
    "model = model_tools.load_network(weight_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_path = \"../data/weights/weights.47.h5\"\n",
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_num = 'run_eval'\n",
    "\n",
    "val_with_targ, pred_with_targ = model_tools.write_predictions_grade_set(model,\n",
    "                                        run_num,'patrol_with_targ', 'sample_evaluation_data') \n",
    "\n",
    "val_no_targ, pred_no_targ = model_tools.write_predictions_grade_set(model, \n",
    "                                        run_num,'patrol_non_targ', 'sample_evaluation_data') \n",
    "\n",
    "val_following, pred_following = model_tools.write_predictions_grade_set(model,\n",
    "                                        run_num,'following_images', 'sample_evaluation_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of validation samples intersection over the union evaulated on 542\n",
      "average intersection over union for background is 0.9956002089284365\n",
      "average intersection over union for other people is 0.3589360492607247\n",
      "average intersection over union for the hero is 0.9184461995650554\n",
      "number true positives: 539, number false positives: 0, number false negatives: 0\n"
     ]
    }
   ],
   "source": [
    "# Scores for while the quad is following behind the target. \n",
    "true_pos1, false_pos1, false_neg1, iou1 = scoring_utils.score_run_iou(val_following, pred_following)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of validation samples intersection over the union evaulated on 270\n",
      "average intersection over union for background is 0.9872087231024474\n",
      "average intersection over union for other people is 0.7298535486332626\n",
      "average intersection over union for the hero is 0.0\n",
      "number true positives: 0, number false positives: 85, number false negatives: 0\n"
     ]
    }
   ],
   "source": [
    "# Scores for images while the quad is on patrol and the target is not visable\n",
    "true_pos2, false_pos2, false_neg2, iou2 = scoring_utils.score_run_iou(val_no_targ, pred_no_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of validation samples intersection over the union evaulated on 322\n",
      "average intersection over union for background is 0.9961998758988091\n",
      "average intersection over union for other people is 0.44239500501380263\n",
      "average intersection over union for the hero is 0.2526181898718522\n",
      "number true positives: 136, number false positives: 5, number false negatives: 165\n"
     ]
    }
   ],
   "source": [
    "# This score measures how well the neural network can detect the target from far away\n",
    "true_pos3, false_pos3, false_neg3, iou3 = scoring_utils.score_run_iou(val_with_targ, pred_with_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7258064516129032\n"
     ]
    }
   ],
   "source": [
    "# Sum all the true positives, etc from the three datasets to get a weight for the score\n",
    "true_pos = true_pos1 + true_pos2 + true_pos3\n",
    "false_pos = false_pos1 + false_pos2 + false_pos3\n",
    "false_neg = false_neg1 + false_neg2 + false_neg3\n",
    "\n",
    "weight = true_pos/(true_pos+false_neg+false_pos)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.585532194718\n"
     ]
    }
   ],
   "source": [
    "# The IoU for the dataset that never includes the hero is excluded from grading\n",
    "final_IoU = (iou1 + iou3)/2\n",
    "print(final_IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.424983044554\n"
     ]
    }
   ],
   "source": [
    "# And the final grade score is \n",
    "final_score = final_IoU * weight\n",
    "print(final_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
